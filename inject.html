<!DOCTYPE html>
<html>
  <body
    style="padding:10px;margin:0px;width:100vw;height:100vh;box-sizing:border-box;display:grid;grid-template-rows:auto 1fr"
  >
    <div>
      <button onclick="on_download_file()">dt file</button>
      <span id="id_info">dt size: loading..</span>
    </div>
    <textarea
      id="texty"
      style="width:100%;height:100%"
      autofocus
      readonly
      placeholder="loading.."
    ></textarea>
  </body>
  <script type="module">
    let port = 60402;
    let braid = load_braid_http();

    import {
      default as init,
      Doc,
      OpLog,
    } from "https://unpkg.com/diamond-types-web";

    let last_text = "";

    let sent_count = 0;
    let ack_count = 0;

    async function main() {
      await init();

      let textarea = document.querySelector("#texty");
      let oplog = new OpLog(crypto.randomUUID());

      window.on_download_file = () => {
        let bytes = oplog.toBytes();
        const blob = new Blob([bytes.buffer], {
          type: "application/octet-stream",
        });
        const url = URL.createObjectURL(blob);

        const link = document.createElement("a");
        link.href = url;
        link.download = "oplog.bytes";
        link.click();

        setTimeout(() => URL.revokeObjectURL(url), 60000); // Cleanup after download
      };

      textarea.addEventListener("input", async () => {
        let commonStart = 0;
        while (
          commonStart < Math.min(last_text.length, textarea.value.length) &&
          last_text[commonStart] == textarea.value[commonStart]
        ) {
          commonStart++;
        }

        let commonEnd = 0;
        while (
          commonEnd <
            Math.min(
              last_text.length - commonStart,
              textarea.value.length - commonStart
            ) &&
          last_text[last_text.length - commonEnd - 1] ==
            textarea.value[textarea.value.length - commonEnd - 1]
        ) {
          commonEnd++;
        }

        let splicePos = commonStart;
        let numToDelete = last_text.length - commonStart - commonEnd;
        let stuffToInsert = textarea.value.slice(
          commonStart,
          textarea.value.length - commonEnd
        );

        last_text = textarea.value;

        let v = oplog.getLocalVersion();
        oplog.del(splicePos, numToDelete);
        oplog.ins(splicePos, stuffToInsert);

        for (let p of OpLog_get_patches(
          oplog.getPatchSince(v),
          oplog.getOpsSince(v)
        )) {
          //   console.log(JSON.stringify(p));

          sent_count++;
          console.log(`s counts: ${ack_count}/${sent_count}`);

          let maxWait = 3000; // 3 seconds
          let waitTime = 100;

          const fetchWithRetry = (url, options) => {
            return braid.fetch(url, options).then(async (x) => {
              if (x.status !== 200) {
                console.log(`got BAD!`);

                waitTime *= 2;
                if (waitTime > maxWait) {
                  waitTime = maxWait;
                }

                console.log(`Retrying in ${waitTime / 1000} seconds...`);

                setTimeout(() => {
                  fetchWithRetry(url, options);
                }, waitTime);
              } else {
                // work here
                let got = await x.text();
                if (got == "ok!") {
                  ack_count++;
                } else {
                  console.log(`bad 200: ${got}`);
                }

                console.log(`a counts: ${ack_count}/${sent_count}`);
              }
            });
          };

          fetchWithRetry("https://test.bloop.monster:" + port, {
            method: "POST",
            mode: "cors",
            version: p.version,
            parents: p.parents,
            patches: [
              {
                unit: "json",
                range: p.range,
                content: p.content,
              },
            ],
          });
        }
      });

      async function connect() {
        try {
          (
            await braid.fetch("https://test.bloop.monster:" + port, {
              subscribe: true,
            })
          ).subscribe(
            ({ version, parents, body, patches }) => {
              //   console.log(
              //     `v = ${JSON.stringify(
              //       { version, parents, body, patches },
              //       null,
              //       4
              //     )}`
              //   );

              if (textarea.hasAttribute("readonly")) {
                textarea.removeAttribute("readonly");
                textarea.placeholder = "type message here..";
              }

              if (!patches) return;

              let v = oplog.getLocalVersion();

              let range = patches[0].range.split("-").map((x) => parseInt(x));

              oplog.addFromBytes(
                OpLog_create_bytes(
                  version,
                  parents,
                  range[0],
                  range[1] - range[0],
                  patches[0].content
                )
              );

              let sel = [textarea.selectionStart, textarea.selectionEnd];

              if (textarea.value != last_text)
                throw new Error("textarea out of sync somehow!");

              // work here
              // console.log(`op log = ${JSON.stringify(oplog.getXFSince(v), null, 4)}`)

              let [new_text, new_sel] = applyChanges(
                textarea.value,
                sel,
                oplog.getXFSince(v)
              );

              textarea.value = last_text = new_text;
              textarea.selectionStart = new_sel[0];
              textarea.selectionEnd = new_sel[1];

              id_info.textContent = `dt size: ${oplog.toBytes().length} bytes`;
            },
            (e) => {
              console.log(`e = ${e}`);
              setTimeout(connect, 1000);
            }
          );
        } catch (e) {
          console.log(`e = ${e}`);
          setTimeout(connect, 1000);
        }
      }
      connect();
    }

    window.addEventListener("DOMContentLoaded", main);

    function applyChanges(original, sel, changes) {
      for (var change of changes) {
        switch (change.kind) {
          case "Del":
            for (let i = 0; i < sel.length; i++) {
              if (sel[i] > change.start) {
                if (sel[i] > change.end) {
                  sel[i] -= change.end - change.start;
                } else sel[i] = change.start;
              }
            }

            original =
              original.substring(0, change.start) +
              original.substring(change.end);
            break;
          case "Ins":
            for (let i = 0; i < sel.length; i++) {
              if (sel[i] > change.start) {
                sel[i] += change.content.length;
              }
            }

            original =
              original.substring(0, change.start) +
              change.content +
              original.substring(change.start);
            break;
          default:
            throw new Error(`Unsupported change kind: ${change.kind}`);
        }
      }
      return [original, sel];
    }

    function load_braid_http() {
      var peer = Math.random().toString(36).substr(2);

      // ***************************
      // http
      // ***************************

      function braidify_http(http) {
        // Todo:  Wrap .put to add `peer` header
        http.normal_get = http.get;
        http.get = function braid_req(arg1, arg2, arg3) {
          var url, options, cb;

          // http.get() supports two forms:
          //
          //  - http.get(url[, options][, callback])
          //  - http.get(options[, callback])
          //
          // We need to know which arguments are which, so let's detect which
          // form we are looking at.

          // Detect form #1: http.get(url[, options][, callback])
          if (typeof arg1 === "string" || arg1 instanceof URL) {
            url = arg1;
            if (typeof arg2 === "function") cb = arg2;
            else {
              options = arg2;
              cb = arg3;
            }
          }

          // Otherwise it's form #2: http.get(options[, callback])
          else {
            options = arg2;
            cb = arg3;
          }

          options = options || {};

          // Now we know where the `options` are specified, let's set headers.
          if (!options.headers) options.headers = {};

          // Add the subscribe header if this is a subscription
          if (options.subscribe) options.headers.subscribe = "true";

          // Always add the `peer` header
          options.headers.peer = options.headers.peer || peer;

          // Wrap the callback to provide our new .on('version', ...) feature
          var on_version,
            on_error,
            orig_cb = cb;
          cb = (res) => {
            res.orig_on = res.on;
            res.on = (key, f) => {
              // Define .on('version', cb)
              if (key === "version") {
                // If we have an 'version' handler, let's remember it
                on_version = f;

                // And set up a subscription parser
                var parser = subscription_parser((version, error) => {
                  if (!error) on_version && on_version(version);
                  else on_error && on_error(error);
                });

                // That will run each time we get new data
                res.orig_on("data", (chunk) => {
                  parser.read(chunk.toString());
                });
              }

              // Forward .on('error', cb) and remember the error function
              else if (key === "error") {
                on_error = f;
                res.orig_on(key, f);
              }

              // Forward all other .on(*, cb) calls
              else res.orig_on(key, f);
            };
            orig_cb && orig_cb(res);
          };

          // Now put the parameters back in their prior order and call the
          // underlying .get() function
          if (url) {
            arg1 = url;
            if (options) {
              arg2 = options;
              arg3 = cb;
            } else {
              arg2 = cb;
            }
          } else {
            arg1 = options;
            arg2 = cb;
          }

          return http.normal_get(arg1, arg2, arg3);
        };
        return http;
      }

      // ***************************
      // Fetch
      // ***************************

      var normal_fetch,
        AbortController,
        Headers,
        is_nodejs = typeof window === "undefined";

      if (is_nodejs) {
        // Nodejs

        // Note that reconnect logic doesn't work in node-fetch, because it
        // doesn't call the .catch() handler when the stream fails.
        //
        // See https://github.com/node-fetch/node-fetch/issues/753

        normal_fetch = require("node-fetch");
        AbortController = require("abort-controller");
        Headers = normal_fetch.Headers;
        var to_whatwg_stream = require("node-web-streams").toWebReadableStream;
      } else {
        // Web Browser
        normal_fetch = window.fetch;
        AbortController = window.AbortController;
        Headers = window.Headers;
        // window.fetch = braid_fetch
      }

      async function braid_fetch(url, params = {}) {
        // Initialize the headers object
        if (!params.headers) params.headers = new Headers();
        if (!(params.headers instanceof Headers))
          params.headers = new Headers(params.headers);

        // Always set the peer
        params.headers.set("peer", peer);

        // We provide some shortcuts for Braid params
        if (params.version)
          params.headers.set("version", JSON.stringify(params.version));
        if (params.parents)
          params.headers.set(
            "parents",
            params.parents.map(JSON.stringify).join(", ")
          );
        if (params.subscribe) params.headers.set("subscribe", "true");

        // Prevent browsers from going to disk cache
        params.cache = "no-cache";

        // Prepare patches
        if (params.patches) {
          console.assert(
            Array.isArray(params.patches),
            "Patches must be array"
          );
          console.assert(!params.body, "Cannot send both patches and body");

          params.patches = params.patches || [];
          params.headers.set("patches", params.patches.length);
          params.body = params.patches
            .map((patch) => {
              var length = `content-length: ${patch.content.length}`;
              var range = `content-range: ${patch.unit} ${patch.range}`;
              return `${length}\r\n${range}\r\n\r\n${patch.content}\r\n`;
            })
            .join("\r\n");
        }

        // Wrap the AbortController with a new one that we control.
        //
        // This is because we want to be able to abort the fetch that the user
        // passes in.  However, the fetch() command uses a silly "AbortController"
        // abstraction to abort fetches, which has both a `signal` and a
        // `controller`, and only passes the signal to fetch(), but we need the
        // `controller` to abort the fetch itself.

        var original_signal = params.signal;
        var underlying_aborter = new AbortController();
        params.signal = underlying_aborter.signal;
        if (original_signal)
          original_signal.addEventListener("abort", () =>
            underlying_aborter.abort()
          );

        // Now we run the original fetch....
        var res = await normal_fetch(url, params);

        // And customize the response with a couple methods for getting
        // the braid subscription data:
        res.subscribe = start_subscription;
        res.subscription = { [Symbol.asyncIterator]: iterator };

        // Now we define the subscription function we just used:
        function start_subscription(cb, error) {
          if (!res.ok) throw new Error("Request returned not ok", res);

          if (res.bodyUsed)
            // TODO: check if this needs a return
            throw new Error("This response's body has already been read", res);

          // Parse the streamed response
          handle_fetch_stream(
            res.body,

            // Each time something happens, we'll either get a new
            // version back, or an error.
            (result, err) => {
              if (!err)
                // Yay!  We got a new version!  Tell the callback!
                cb(result);
              else {
                // This error handling code runs if the connection
                // closes, or if there is unparseable stuff in the
                // streamed response.

                // In any case, we want to be sure to abort the
                // underlying fetch.
                underlying_aborter.abort();

                // Then send the error upstream.
                if (error) error(err);
                else throw "Unhandled network error in subscription";
              }
            }
          );
        }

        // And the iterator for use with "for async (...)"
        function iterator() {
          // We'll keep this state while our iterator runs
          var initialized = false,
            inbox = [],
            resolve = null,
            reject = null;

          return {
            async next() {
              // If we've already received a version, return it
              if (inbox.length > 0)
                return { done: false, value: inbox.shift() };

              // Otherwise, let's set up a promise to resolve when we get the next item
              var promise = new Promise((_resolve, _reject) => {
                resolve = _resolve;
                reject = _reject;
              });

              // Start the subscription, if we haven't already
              if (!initialized) {
                initialized = true;

                // The subscription will call whichever resolve and
                // reject functions the current promise is waiting for
                start_subscription(
                  (x) => resolve(x),
                  (x) => reject(x)
                );
              }

              // Now wait for the subscription to resolve or reject the promise.
              var result = await promise;

              // Anything we get from here out we should add to the inbox
              resolve = (new_version) => inbox.push(new_version);
              reject = (err) => {
                throw err;
              };

              return { done: false, value: result };
            },
          };
        }

        return res;
      }

      // Parse a stream of versions from the incoming bytes
      async function handle_fetch_stream(stream, cb) {
        if (is_nodejs) stream = to_whatwg_stream(stream);

        // Set up a reader
        var reader = stream.getReader(),
          decoder = new TextDecoder("utf-8"),
          parser = subscription_parser(cb);

        while (true) {
          var versions = [];

          try {
            // Read the next chunk of stream!
            var { done, value } = await reader.read();

            // Check if this connection has been closed!
            if (done) {
              console.debug("Connection closed.");
              cb(null, "Connection closed");
              return;
            }

            // Tell the parser to process some more stream
            parser.read(decoder.decode(value));
          } catch (e) {
            cb(null, e);
            return;
          }
        }
      }

      // ****************************
      // Braid-HTTP Subscription Parser
      // ****************************

      var subscription_parser = (cb) => ({
        // A parser keeps some parse state
        state: { input: "" },

        // And reports back new versions as soon as they are ready
        cb: cb,

        // You give it new input information as soon as you get it, and it will
        // report back with new versions as soon as it finds them.
        read(input) {
          // Store the new input!
          this.state.input += input;

          // Now loop through the input and parse until we hit a dead end
          do {
            this.state = parse_version(this.state);

            // Maybe we parsed a version!  That's cool!
            if (this.state.result === "success") {
              this.cb({
                version: this.state.version,
                parents: this.state.parents,
                body: this.state.body,
                patches: this.state.patches,
              });

              // Reset the parser for the next version!
              this.state = { input: this.state.input };
            }

            // Or maybe there's an error to report upstream
            else if (this.state.result === "error") {
              this.cb(null, this.state.message);
              return;
            }

            // We stop once we've run out of parseable input.
          } while (
            this.state.result !== "waiting" &&
            this.state.input.trim() !== ""
          );
        },
      });

      // ****************************
      // General parsing functions
      // ****************************
      //
      // Each of these functions takes parsing state as input, mutates the state,
      // and returns the new state.
      //
      // Depending on the parse result, each parse function returns:
      //
      //  parse_<thing> (state)
      //  => {result: 'waiting', ...}  If it parsed part of an item, but neeeds more input
      //  => {result: 'success', ...}  If it parses an entire item
      //  => {result: 'error', ...}    If there is a syntax error in the input

      function parse_version(state) {
        // If we don't have headers yet, let's try to parse some
        if (!state.headers) {
          var parsed = parse_headers(state.input);

          // If header-parsing fails, send the error upstream
          if (parsed.result === "error") return parsed;
          if (parsed.result === "waiting") {
            state.result = "waiting";
            return state;
          }

          state.headers = parsed.headers;
          state.version = state.headers.version;
          state.parents = state.headers.parents;

          // Take the parsed headers out of the buffer
          state.input = parsed.input;
        }

        // We have headers now!  Try parsing more body.
        return parse_body(state);
      }

      function swallow_blank_lines(input) {
        var blank_lines = /(\r\n|\n)*/.exec(input)[0];
        return input.substr(blank_lines.length);
      }

      // Parsing helpers
      function parse_headers(input) {
        input = swallow_blank_lines(input);

        // First, find the start & end block of the headers.  The headers start
        // when there are no longer newlines, and end at the first double-newline.

        // Look for the double-newline at the end of the headers
        var headers_end = input.match(/(\r?\n)\r?\n/);

        // ...if we found none, then we need to wait for more input to complete
        // the headers..
        if (!headers_end) return { result: "waiting" };

        // We now know where the headers are to parse!
        var headers_length = headers_end.index + headers_end[1].length,
          headers_source = input.substring(0, headers_length);

        // Let's parse them!  First define some variables:
        var headers = {},
          header_regex = /([\w-_]+):\s?(.*)\r?\n/gy, // Parses one line a time
          match,
          found_last_match = false;

        // And now loop through the block, matching one line at a time
        while ((match = header_regex.exec(headers_source))) {
          // console.log('Header match:', match && [match[1], match[2]])
          headers[match[1].toLowerCase()] = match[2];

          // This might be the last line of the headers block!
          if (header_regex.lastIndex === headers_length)
            found_last_match = true;
        }

        // If the regex failed before we got to the end of the block, throw error:
        if (!found_last_match)
          return {
            result: "error",
            message:
              'Parse error in headers: "' +
              JSON.stringify(headers_source.substr(header_regex.lastIndex)) +
              '"',
            headers_so_far: headers,
            last_index: header_regex.lastIndex,
            headers_length,
          };

        // Success!  Let's parse special headers
        if ("version" in headers) headers.version = JSON.parse(headers.version);
        if ("parents" in headers)
          headers.parents = JSON.parse("[" + headers.parents + "]");
        if ("patches" in headers) headers.patches = JSON.parse(headers.patches);

        // Update the input
        input = input.substring(headers_length);

        // Swallow the final blank line ending the headers
        if (input.substr(0, 2) === "\r\n")
          // Swallow \r\n
          input = input.substr(2);
        // Swallow \n
        else input = input.substr(1);

        // And return the parsed result
        return { result: "success", headers, input };
      }

      function parse_body(state) {
        // Parse Body Snapshot

        var content_length = parseInt(state.headers["content-length"]);
        if (!isNaN(content_length)) {
          if (content_length > state.input.length) {
            state.result = "waiting";
            return state;
          }

          var consumed_length = content_length + 2;
          state.result = "success";
          state.body = state.input.substring(0, content_length);
          state.input = state.input.substring(consumed_length);
          return state;
        }

        // Parse Patches
        else if (state.headers.patches) {
          state.patches = state.patches || [];

          var last_patch = state.patches[state.patches.length - 1];

          // Parse patches until the final patch has its content filled
          while (
            !(
              state.patches.length === state.headers.patches &&
              "content" in last_patch
            )
          ) {
            state.input = state.input.trimStart();

            // Are we starting a new patch?
            if (!last_patch || "content" in last_patch) {
              last_patch = {};
              state.patches.push(last_patch);
            }

            // Parse patch headers
            if (!("headers" in last_patch)) {
              var parsed = parse_headers(state.input);

              // If header-parsing fails, send the error upstream
              if (parsed.result === "error") return parsed;
              if (parsed.result === "waiting") {
                state.result = "waiting";
                return state;
              }

              // We parsed patch headers!  Update state.
              last_patch.headers = parsed.headers;
              state.input = parsed.input;
            }

            // Todo: support arbitrary patches, not just range-patch

            // Parse Range Patch format
            {
              if (!("content-length" in last_patch.headers))
                return {
                  result: "error",
                  message: "no content-length in patch",
                  patch: last_patch,
                  input: state.input,
                };

              if (!("content-range" in last_patch.headers))
                return {
                  result: "error",
                  message: "no content-range in patch",
                  patch: last_patch,
                  input: state.input,
                };

              var content_length = parseInt(
                last_patch.headers["content-length"]
              );

              // Does input have the entire patch contents yet?
              if (state.input.length < content_length) {
                state.result = "waiting";
                return state;
              }

              // Content-range is of the form '<unit> <range>' e.g. 'json .index'

              var match =
                last_patch.headers["content-range"].match(/(\S+) (.*)/);
              if (!match)
                return {
                  result: "error",
                  message: "cannot parse content-range in patch",
                  patch: last_patch,
                  input: state.input,
                };

              last_patch.unit = match[1];
              last_patch.range = match[2];
              last_patch.content = state.input.substr(0, content_length);

              // Consume the parsed input
              state.input = state.input.substring(content_length);
            }
          }

          state.result = "success";
          return state;
        }

        return {
          result: "error",
          message: "cannot parse body without content-length or patches header",
        };
      }

      // ****************************
      // Exports
      // ****************************

      return {
        fetch: braid_fetch,
        http: braidify_http,
        subscription_parser,
        parse_version,
        parse_headers,
        parse_body,
      };
    }

    function OpLog_get_patches(bytes, op_runs) {
      //   console.log(`bytes = `, bytes);

      let ops = [];
      for (let op_run of op_runs) {
        let len = op_run.end - op_run.start;
        for (let i = 0; i < len; i++) {
          ops.push({
            range: op_run.content
              ? `${op_run.start + i}-${op_run.start + i}`
              : `${op_run.start}-${op_run.start + 1}`,
            insert: (op_run.content || "").slice(i, i + 1),
          });
        }
      }

      //   console.log(`ops = ${JSON.stringify(ops, null, 4)}`);

      let [agents, versions, parentss] = parseDT([...bytes]);

      //   console.log(JSON.stringify({ agents, versions, parentss }, null, 4));

      return versions.map((v, i) => {
        // console.log(`v = ${v}, i = ${i}`);
        return {
          version: JSON.stringify(v),
          parents: parentss[i].map((x) => JSON.stringify(x)),
          unit: "json",
          range: ops[i].range,
          content: ops[i].insert,
        };
      });

      function parseDT(byte_array) {
        if (
          new TextDecoder().decode(new Uint8Array(byte_array.splice(0, 8))) !==
          "DMNDTYPS"
        )
          throw new Error("dt parse error, expected DMNDTYPS");

        if (byte_array.shift() != 0)
          throw new Error("dt parse error, expected version 0");

        let agents = [];
        let versions = [];
        let parentss = [];

        while (byte_array.length) {
          let id = byte_array.shift();
          let len = read_varint(byte_array);
          if (id == 1) {
          } else if (id == 3) {
            let goal = byte_array.length - len;
            while (byte_array.length > goal) {
              agents.push(read_string(byte_array));
            }
          } else if (id == 20) {
          } else if (id == 21) {
            let seqs = {};
            let goal = byte_array.length - len;
            while (byte_array.length > goal) {
              let part0 = read_varint(byte_array);
              let has_jump = part0 & 1;
              let agent_i = (part0 >> 1) - 1;
              let run_length = read_varint(byte_array);
              let jump = 0;
              if (has_jump) {
                let part2 = read_varint(byte_array);
                jump = part2 >> 1;
                if (part2 & 1) jump *= -1;
              }
              let base = (seqs[agent_i] || 0) + jump;

              for (let i = 0; i < run_length; i++) {
                versions.push([agents[agent_i], base + i]);
              }
              seqs[agent_i] = base + run_length;
            }
          } else if (id == 23) {
            let count = 0;
            let goal = byte_array.length - len;
            while (byte_array.length > goal) {
              let run_len = read_varint(byte_array);

              let parents = [];
              let has_more = 1;
              while (has_more) {
                let x = read_varint(byte_array);
                let is_foreign = 0x1 & x;
                has_more = 0x2 & x;
                let num = x >> 2;

                if (x == 1) {
                  parents.push(["root"]);
                } else if (!is_foreign) {
                  parents.push(versions[count - num]);
                } else {
                  parents.push([agents[num - 1], read_varint(byte_array)]);
                }
              }
              parentss.push(parents);
              count++;

              for (let i = 0; i < run_len - 1; i++) {
                parentss.push([versions[count - 1]]);
                count++;
              }
            }
          } else {
            byte_array.splice(0, len);
          }
        }

        function read_string(byte_array) {
          return new TextDecoder().decode(
            new Uint8Array(byte_array.splice(0, read_varint(byte_array)))
          );
        }

        function read_varint(byte_array) {
          let result = 0;
          let shift = 0;
          while (true) {
            if (byte_array.length === 0)
              throw new Error("byte array does not contain varint");

            let byte_val = byte_array.shift();
            result |= (byte_val & 0x7f) << shift;
            if ((byte_val & 0x80) == 0) return result;
            shift += 7;
          }
        }

        return [agents, versions, parentss];
      }
    }

    function OpLog_create_bytes(version, parents, pos, del, ins) {
      //   console.log(
      //     `args = ${JSON.stringify({ version, parents, pos, del, ins }, null, 4)}`
      //   );

      function write_varint(bytes, value) {
        while (value >= 0x80) {
          bytes.push((value & 0x7f) | 0x80);
          value >>= 7;
        }
        bytes.push(value);
      }

      function write_string(byte_array, str) {
        let str_bytes = new TextEncoder().encode(str);
        write_varint(byte_array, str_bytes.length);
        byte_array.push(...str_bytes);
      }

      version = JSON.parse(version);
      parents = parents.map((x) => JSON.parse(x));

      let bytes = [];
      bytes = bytes.concat(Array.from(new TextEncoder().encode("DMNDTYPS")));
      bytes.push(0);

      let file_info = [];
      let agent_names = [];

      let agents = new Set();
      agents.add(version[0]);
      for (let p of parents) if (p.length > 1) agents.add(p[0]);
      agents = [...agents];

      //   console.log(JSON.stringify({ agents, parents }, null, 4));

      let agent_to_i = {};
      for (let [i, agent] of agents.entries()) {
        agent_to_i[agent] = i;
        write_string(agent_names, agent);
      }

      file_info.push(3);
      write_varint(file_info, agent_names.length);
      file_info.push(...agent_names);

      bytes.push(1);
      write_varint(bytes, file_info.length);
      bytes.push(...file_info);

      let branch = [];

      if (parents[0].length > 1) {
        let frontier = [];

        for (let [i, [agent, seq]] of parents.entries()) {
          let has_more = i < parents.length - 1;
          let mapped = agent_to_i[agent];
          let n = ((mapped + 1) << 1) | (has_more ? 1 : 0);
          write_varint(frontier, n);
          write_varint(frontier, seq);
        }

        branch.push(12);
        write_varint(branch, frontier.length);
        branch.push(...frontier);
      }

      bytes.push(10);
      write_varint(bytes, branch.length);
      bytes.push(...branch);

      let patches = [];

      if (ins) {
        let inserted_content_bytes = [];

        inserted_content_bytes.push(0); // ins (not del, which is 1)

        inserted_content_bytes.push(13); // "content" enum (rather than compressed)
        inserted_content_bytes.push(2); // length of content chunk
        inserted_content_bytes.push(4); // "plain text" enum
        inserted_content_bytes.push(ins.charCodeAt(0)); // actual text

        inserted_content_bytes.push(25); // "known" enum
        inserted_content_bytes.push(1); // length of "known" chunk
        inserted_content_bytes.push(3); // content of length 1, and we "know" it

        patches.push(24);
        write_varint(patches, inserted_content_bytes.length);
        patches.push(...inserted_content_bytes);
      }

      if (true) {
        let version_bytes = [];

        let [agent, seq] = version;
        let agent_i = agent_to_i[agent];
        let jump = seq;

        write_varint(version_bytes, ((agent_i + 1) << 1) | (jump != 0 ? 1 : 0));
        write_varint(version_bytes, 1);
        if (jump) write_varint(version_bytes, jump << 1);

        patches.push(21);
        write_varint(patches, version_bytes.length);
        patches.push(...version_bytes);
      }

      if (true) {
        let op_bytes = [];

        write_varint(op_bytes, (pos << 4) | (pos ? 2 : 0) | (ins ? 0 : 4));

        patches.push(22);
        write_varint(patches, op_bytes.length);
        patches.push(...op_bytes);
      }

      if (true) {
        let parents_bytes = [];

        write_varint(parents_bytes, 1);

        if (parents[0].length > 1) {
          for (let [i, [agent, seq]] of parents.entries()) {
            let has_more = i < parents.length - 1;
            let agent_i = agent_to_i[agent];
            write_varint(
              parents_bytes,
              ((agent_i + 1) << 2) | (has_more ? 2 : 0) | 1
            );
            write_varint(parents_bytes, seq);
          }
        } else write_varint(parents_bytes, 1);

        patches.push(23);
        write_varint(patches, parents_bytes.length);
        patches.push(...parents_bytes);
      }

      bytes.push(20);
      write_varint(bytes, patches.length);
      bytes.push(...patches);

      //   console.log(bytes);

      return bytes;
    }

    // GOOD
    // Uint8Array(51) [
    //   68,  77, 78,  68,  84,  89,  80,  83,   0,  1, 9,
    //    3,   7,  6, 115, 101, 114, 118, 101, 114, 10, 0,
    //   20,  21,

    //   21,  2,   2,   1,
    //   22,   1,   0,
    //   23,  2, 1, 1,
    //   24,   8,   0,  13,   2,   4, 104, 25, 1, 3,
    // ]

    // what we did:
    // [68, 77, 78, 68, 84, 89, 80, 83, 0, 1, 9,
    // 3, 7, 6, 115, 101, 114, 118, 101, 114, 10, 0,
    // 20, 21,

    // 21, 2, 2, 1,
    // 22, 1, 0,
    // 23, 2, 1, 1,
    // 24, 8, 0, 13, 2, 4, 104, 25, 1, 3]

    // [68, 77, 78, 68, 84, 89, 80, 83, 0, 1, 9, 3, 7, 6, 115, 101, 114, 118, 101, 114, 10, 0, 20, 21, 21, 2, 2, 1, 22, 1, 0, 23, 2, 1, 1, 24, 8, 0, 13, 2, 4, 104, 25, 1, 3]
  </script>
</html>
